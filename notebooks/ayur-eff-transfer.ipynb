{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport pandas as pd\nimport multiprocessing as mp\nimport torchvision\nimport timm\n\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, datasets, models\nfrom torchvision.transforms.functional import InterpolationMode\nfrom transformers import get_cosine_schedule_with_warmup\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:21.733132Z","iopub.execute_input":"2023-09-16T14:29:21.735345Z","iopub.status.idle":"2023-09-16T14:29:28.015481Z","shell.execute_reply.started":"2023-09-16T14:29:21.735307Z","shell.execute_reply":"2023-09-16T14:29:28.014045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"F2aSznx6vyycTtjQ4IqS\")\nproject = rf.workspace(\"ayurved\").project(\"ayurved\")\ndataset = project.version(2).download(\"folder\")","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:28.016948Z","iopub.execute_input":"2023-09-16T14:29:28.017623Z","iopub.status.idle":"2023-09-16T14:29:43.998550Z","shell.execute_reply.started":"2023-09-16T14:29:28.017586Z","shell.execute_reply":"2023-09-16T14:29:43.997462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OS ENV SETUP\n\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\nos.environ[\"MKL_NUM_THREADS\"] = \"1\"\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\nos.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n\n# CONFIG\n\n\nDATA_DIR = '/kaggle/working/Ayurved-2'\nTEST_DIR = '/kaggle/working/Ayurved-2/test/Test'\nTRAIN_DIR ='/kaggle/working/Ayurved-2/train'\nSUB_DIR = '/kaggle/working/image_species.csv'\nW_PATH = '/kaggle/input/test-file-model/ayurmodelstate.pth'\nSEED = 279\nTRAIN_BS = 8\nTEST_BS = 100\nNUM_CLASSES = 6\nEMBEDDING_SIZE = 1280\nNUM_EPOCHS = 14\nLEARNING_RATE = 0.0003\nWEIGHT_DECAY = 0\nWARMUP_EPOCHS = 0\nLOGGING_INTERVAL = 100\nN_CORES = mp.cpu_count()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.000127Z","iopub.execute_input":"2023-09-16T14:29:44.000899Z","iopub.status.idle":"2023-09-16T14:29:44.009360Z","shell.execute_reply.started":"2023-09-16T14:29:44.000858Z","shell.execute_reply":"2023-09-16T14:29:44.008186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    DEVICE = torch.device(type='cuda')\nelse:\n    DEVICE = torch.device('cpu')\n\nprint(f'USING device: {DEVICE}')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.013140Z","iopub.execute_input":"2023-09-16T14:29:44.013535Z","iopub.status.idle":"2023-09-16T14:29:44.045203Z","shell.execute_reply.started":"2023-09-16T14:29:44.013510Z","shell.execute_reply":"2023-09-16T14:29:44.044320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.046501Z","iopub.execute_input":"2023-09-16T14:29:44.047271Z","iopub.status.idle":"2023-09-16T14:29:44.059965Z","shell.execute_reply.started":"2023-09-16T14:29:44.047233Z","shell.execute_reply":"2023-09-16T14:29:44.058771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.061547Z","iopub.execute_input":"2023-09-16T14:29:44.062181Z","iopub.status.idle":"2023-09-16T14:29:44.072487Z","shell.execute_reply.started":"2023-09-16T14:29:44.062144Z","shell.execute_reply":"2023-09-16T14:29:44.071569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = os.listdir(TRAIN_DIR)\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.074093Z","iopub.execute_input":"2023-09-16T14:29:44.074441Z","iopub.status.idle":"2023-09-16T14:29:44.082363Z","shell.execute_reply.started":"2023-09-16T14:29:44.074407Z","shell.execute_reply":"2023-09-16T14:29:44.081235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files = os.listdir(TEST_DIR)\ntest_df = pd.DataFrame({'file_path': test_files})\ntest_df['label'] = 9999","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.083956Z","iopub.execute_input":"2023-09-16T14:29:44.084456Z","iopub.status.idle":"2023-09-16T14:29:44.094110Z","shell.execute_reply.started":"2023-09-16T14:29:44.084424Z","shell.execute_reply":"2023-09-16T14:29:44.093184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# COnfiguring Data Set\n\nclass PlantDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.file_path = df['file_path']\n        self.y = df['label']\n\n    def __getitem__(self, index):\n        img = Image.open(os.path.join(self.img_dir, self.file_path[index]))\n        if self.transform is not None:\n            img = self.transform(img)\n        label = self.y[index]\n        return img, label\n\n    def __len__(self):\n        return self.y.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.095643Z","iopub.execute_input":"2023-09-16T14:29:44.096060Z","iopub.status.idle":"2023-09-16T14:29:44.105389Z","shell.execute_reply.started":"2023-09-16T14:29:44.096028Z","shell.execute_reply":"2023-09-16T14:29:44.104457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_4_channel_to_3_channel(image):\n    \"\"\"\n    Convert 4-channel RGBA image to 3-channel RGB image\n    \"\"\"\n    if image.mode == 'RGBA':\n        image = image.convert('RGB')\n    return image\n\n\ndata_transforms = {\n    'train':transforms.Compose([\n    transforms.Lambda(convert_4_channel_to_3_channel),\n    transforms.Resize(\n        size=(250, 250), interpolation=InterpolationMode.BILINEAR),\n    transforms.RandomRotation(degrees=(-180, 180)),\n    transforms.RandomAffine(degrees=0, translate=(0.3, 0.3), scale=(0.7, 1.3)),\n    transforms.RandomCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n]),\n    'valid':transforms.Compose([\n    transforms.Lambda(convert_4_channel_to_3_channel),\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]),\n    }\ntest_transforms = transforms.Compose([\n    transforms.Lambda(convert_4_channel_to_3_channel), \n    transforms.Resize(size=(224, 224), interpolation=InterpolationMode.BILINEAR),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    \n])","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.107666Z","iopub.execute_input":"2023-09-16T14:29:44.107926Z","iopub.status.idle":"2023-09-16T14:29:44.120151Z","shell.execute_reply.started":"2023-09-16T14:29:44.107903Z","shell.execute_reply":"2023-09-16T14:29:44.119435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = PlantDataset(df=test_df,\n                           img_dir=TEST_DIR,\n                           transform=test_transforms)\ntest_loader = DataLoader(dataset=test_dataset,\n                        batch_size=TEST_BS,\n                        drop_last=False,\n                        shuffle=False,\n                        num_workers=N_CORES)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.121406Z","iopub.execute_input":"2023-09-16T14:29:44.122314Z","iopub.status.idle":"2023-09-16T14:29:44.130778Z","shell.execute_reply.started":"2023-09-16T14:29:44.122289Z","shell.execute_reply":"2023-09-16T14:29:44.129789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dataset = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x]) for x in ['train', 'valid']}","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.132528Z","iopub.execute_input":"2023-09-16T14:29:44.133320Z","iopub.status.idle":"2023-09-16T14:29:44.153507Z","shell.execute_reply.started":"2023-09-16T14:29:44.133287Z","shell.execute_reply":"2023-09-16T14:29:44.152691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader ={x:DataLoader(img_dataset[x], batch_size=TRAIN_BS, drop_last=True, shuffle=True, num_workers=N_CORES) for x in ['train','valid']}","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.157815Z","iopub.execute_input":"2023-09-16T14:29:44.158619Z","iopub.status.idle":"2023-09-16T14:29:44.164044Z","shell.execute_reply.started":"2023-09-16T14:29:44.158587Z","shell.execute_reply":"2023-09-16T14:29:44.163105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_sizes = {x: len(img_dataset[x]) for x in ['train', 'valid']}\nclass_names = img_dataset['train'].classes","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.165541Z","iopub.execute_input":"2023-09-16T14:29:44.165983Z","iopub.status.idle":"2023-09-16T14:29:44.174496Z","shell.execute_reply.started":"2023-09-16T14:29:44.165949Z","shell.execute_reply":"2023-09-16T14:29:44.173544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EffNet(nn.Module):\n    def __init__(self, num_classes, embedding_size):\n        super(EffNet, self).__init__()\n        self.num_classes = num_classes\n        self.embedding_size = embedding_size\n        self.backbone = timm.create_model(\n            'efficientnet_b1',\n            pretrained=True,\n            num_classes=self.num_classes\n        )\n        \n        self.backbone.classifier = nn.Sequential(\n            nn.Linear(self.embedding_size,256),\n            nn.BatchNorm1d(256),\n            nn.PReLU(),\n            nn.Linear(256,128),\n            nn.BatchNorm1d(128),\n            nn.PReLU(),\n            nn.Linear(128, self.num_classes)\n            )\n        \n    def forward(self,x):\n        return self.backbone(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.175931Z","iopub.execute_input":"2023-09-16T14:29:44.176451Z","iopub.status.idle":"2023-09-16T14:29:44.185161Z","shell.execute_reply.started":"2023-09-16T14:29:44.176415Z","shell.execute_reply":"2023-09-16T14:29:44.184179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(SEED)\nmodel = EffNet(num_classes=NUM_CLASSES, embedding_size=EMBEDDING_SIZE)\nmodel.to(DEVICE)\n\n# with open('model_state.pt', 'wb') as f: \n#         torch.save(model().state_dict(), f)\n\noptimizer = optim.AdamW(\n    model.parameters(), \n    lr=LEARNING_RATE,\n    weight_decay=WEIGHT_DECAY\n)\n\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=WARMUP_EPOCHS,\n    num_training_steps=dataset_sizes['train']*NUM_EPOCHS\n)\n\nscaler = GradScaler()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:44.186482Z","iopub.execute_input":"2023-09-16T14:29:44.187079Z","iopub.status.idle":"2023-09-16T14:29:46.969958Z","shell.execute_reply.started":"2023-09-16T14:29:44.187046Z","shell.execute_reply":"2023-09-16T14:29:46.968991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model,  optimizer, scaler, scheduler, num_epochs):\n    \n    since = time.time()\n\n    \n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'model_state.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            \n            for phase in ['train', 'valid']:\n                if phase == 'train':\n                    model.train()  \n                else:\n                    model.eval()   \n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloader[phase]:\n                    inputs = inputs.to(DEVICE)\n                    labels = labels.to(DEVICE)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        with autocast():\n                            logits = model(inputs)\n                            _, preds = torch.max(logits, 1)\n                            loss = F.cross_entropy(logits, labels, reduction='mean')\n                        \n                        \n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            scaler.scale(loss).backward()\n                            scaler.step(optimizer)\n                            scaler.update()\n                            optimizer.zero_grad()\n                            scheduler.step()\n\n                    # statistics\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n                if phase == 'train':\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # deep copy the model\n                if phase == 'valid' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best val Acc: {best_acc:4f}')\n\n        # load best model weights\n        model.load_state_dict(torch.load(best_model_params_path))\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:46.971761Z","iopub.execute_input":"2023-09-16T14:29:46.972193Z","iopub.status.idle":"2023-09-16T14:29:46.986766Z","shell.execute_reply.started":"2023-09-16T14:29:46.972159Z","shell.execute_reply":"2023-09-16T14:29:46.985562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_tr = train_model(model,optimizer,scaler, scheduler,NUM_EPOCHS)\n\ntorch.save(model_tr.state_dict(), 'ayurmodelstate.pth')","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:29:46.988161Z","iopub.execute_input":"2023-09-16T14:29:46.989202Z","iopub.status.idle":"2023-09-16T14:33:59.185003Z","shell.execute_reply.started":"2023-09-16T14:29:46.989168Z","shell.execute_reply":"2023-09-16T14:33:59.182959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nmodel.eval()\nwith torch.inference_mode():\n    for features, target in test_loader:\n        features = features.to(DEVICE)\n        target = target.to(DEVICE)\n        \n        with autocast():\n            logits = model(features)\n            \n        y_pred = torch.softmax(logits, dim=1).argmax(dim=1).detach().cpu()\n        \n        for pred in y_pred:\n            preds.append(pred.item())","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:33:59.186866Z","iopub.execute_input":"2023-09-16T14:33:59.187397Z","iopub.status.idle":"2023-09-16T14:34:00.533320Z","shell.execute_reply.started":"2023-09-16T14:33:59.187355Z","shell.execute_reply":"2023-09-16T14:34:00.532010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport csv\n\n\nfolder_path = \"/kaggle/working/Ayurved-2/test/Test\"\n\n\nfile_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n\n\ncsv_file = \"image_species.csv\"\n\nwith open(csv_file, mode=\"w\", newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow([\"file\", \"species\"])  # Write header row\n\n    for file_name in file_names:\n        writer.writerow([file_name, \"neem\"])  # Write file name and species for each picture\n\nprint(f\"CSV file '{csv_file}' created with image names and species 'neem'.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:34:00.535494Z","iopub.execute_input":"2023-09-16T14:34:00.535914Z","iopub.status.idle":"2023-09-16T14:34:00.549056Z","shell.execute_reply.started":"2023-09-16T14:34:00.535877Z","shell.execute_reply":"2023-09-16T14:34:00.548021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_labels = {}\nfor idx, i in enumerate(class_labels):\n    map_labels[idx] = i\n    \nsub_df = pd.read_csv(SUB_DIR)\nsub_df['file'] = test_df['file_path']\nsub_df['species'] = pd.Series(preds).map(map_labels)\nsub_df.to_csv('submisson.csv', index=False)\nprint('Submission file saved!')\nsub_df","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:34:00.551432Z","iopub.execute_input":"2023-09-16T14:34:00.551860Z","iopub.status.idle":"2023-09-16T14:34:00.589236Z","shell.execute_reply.started":"2023-09-16T14:34:00.551827Z","shell.execute_reply":"2023-09-16T14:34:00.588127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = EffNet(num_classes=NUM_CLASSES, embedding_size=EMBEDDING_SIZE)\nmodel.load_state_dict(torch.load(W_PATH))\nimg_path= '/kaggle/input/test-file-model/dumy.jpg'\n\ndef convert_4_channel_to_3_channel(image):\n    \"\"\"\n    Convert 4-channel RGBA image to 3-channel RGB image\n    \"\"\"\n    if image.mode == 'RGBA':\n        image = image.convert('RGB')\n    return image\n\nmy_transforms = transforms.Compose([\n        transforms.Lambda(convert_4_channel_to_3_channel),\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nimage = Image.open(img_path)\nimage = my_transforms(image)\n\nmodel.to(DEVICE)\nmodel.eval()\n\nwith torch.inference_mode():\n    image = image.to(DEVICE)\n    image = image.unsqueeze(0)\n    with autocast():\n        logits = model.forward(image)\n            \n        y_pred = torch.softmax(logits, dim=1).argmax(dim=1).detach().cpu()\n        \n    print(y_pred)\n    \n    predicted_labels = class_labels[y_pred.item()]\n    print(predicted_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T14:35:44.213144Z","iopub.execute_input":"2023-09-16T14:35:44.213561Z","iopub.status.idle":"2023-09-16T14:35:47.151701Z","shell.execute_reply.started":"2023-09-16T14:35:44.213522Z","shell.execute_reply":"2023-09-16T14:35:47.150644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}